{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 56,
=======
   "execution_count": 1,
>>>>>>> main
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r X_train X_test y_grade_train y_grade_test \n",
    "\n",
    "\n",
    "y_train = y_grade_train\n",
    "y_test = y_grade_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'X_train' (DataFrame)\n",
      "Stored 'X_test' (DataFrame)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n"
     ]
    }
   ],
   "source": [
    "%store X_train X_test y_train y_test"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 57,
=======
   "execution_count": 2,
>>>>>>> main
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, classification_report, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 58,
=======
   "execution_count": 3,
>>>>>>> main
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Funktion to printe the scores\n",
    "def score_print(y,y_pred):\n",
    "    \n",
    "    cm = confusion_matrix(y,y_pred)\n",
    "    print(cm)\n",
    "    cp= classification_report(y,y_pred)\n",
    "    print(cp)\n",
    "    #roc = roc_auc_score(y, y_pred)\n",
    "    #print(roc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>G</th>\n",
       "      <td>8335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>8254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>8115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A</th>\n",
       "      <td>8104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>D</th>\n",
       "      <td>8103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>C</th>\n",
       "      <td>8101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F</th>\n",
       "      <td>8059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "G  8335\n",
       "E  8254\n",
       "B  8115\n",
       "A  8104\n",
       "D  8103\n",
       "C  8101\n",
       "F  8059"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grades = pd.DataFrame(y_train.value_counts())\n",
    "grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
=======
   "execution_count": 4,
>>>>>>> main
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Total number of records: 57071\n",
      "Individuals have grades:       0\n",
      "G  8335\n",
      "E  8254\n",
      "B  8115\n",
      "A  8104\n",
      "D  8103\n",
      "C  8101\n",
      "F  8059\n",
      "Individuals have most likely grade: G\n",
      "Individuals have most likely grade with percent: 14.60%\n"
=======
      "Total number of records: 114128\nIndividuals have grades:        0\nA  16304\nD  16304\nC  16304\nE  16304\nF  16304\nB  16304\nG  16304\nIndividuals have most likely grade: A\nIndividuals have most likely grade with percent: 14.29%\n"
>>>>>>> main
     ]
    }
   ],
   "source": [
    "###### Naiv-estimator\n",
    "\n",
    "# TODO: Total number of records\n",
    "n_records = len(y_train)\n",
    "\n",
    "# TODO: Different grades\n",
    "grades = pd.DataFrame(y_train.value_counts())\n",
    "\n",
    "# TODO: Mmost frequent grade \n",
    "most_frequent_grade = grades[grades[0] == int(grades.max())].index.tolist()[0]\n",
    "\n",
    "# TODO: Percentage of individuals whose income is more than $50,000\n",
    "percent = float(100 * grades.max() / n_records)\n",
    "\n",
    "# Print the results\n",
    "print (\"Total number of records: {}\".format(n_records))\n",
    "print (\"Individuals have grades: {}\".format(grades))\n",
    "print (\"Individuals have most likely grade: {}\".format(most_frequent_grade))\n",
    "print (\"Individuals have most likely grade with percent: {:.2f}%\".format(percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2467   78    0    0    0    0    0]\n",
      " [  74 2842  182    0    0    0    0]\n",
      " [   1  114 1864  207    0    0    0]\n",
      " [   2    0  144 1180  178    0    0]\n",
      " [   1    0    0  113  638   97    0]\n",
      " [   0    0    0    0   46  241   38]\n",
      " [   0    0    0    0    0   22  105]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.97      0.97      0.97      2545\n",
      "           B       0.94      0.92      0.93      3098\n",
      "           C       0.85      0.85      0.85      2186\n",
      "           D       0.79      0.78      0.79      1504\n",
      "           E       0.74      0.75      0.75       849\n",
      "           F       0.67      0.74      0.70       325\n",
      "           G       0.73      0.83      0.78       127\n",
      "\n",
      "    accuracy                           0.88     10634\n",
      "   macro avg       0.81      0.83      0.82     10634\n",
      "weighted avg       0.88      0.88      0.88     10634\n",
=======
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[2475   69    0    0    0    0    0]\n",
      " [  76 2821  179    0    0    0    0]\n",
      " [   1  104 1860  183    0    0    0]\n",
      " [   2    0  145 1165  143    0    0]\n",
      " [   1    0    0  117  584  107    0]\n",
      " [   0    0    0    0   45  223   34]\n",
      " [   0    0    0    0    0   26   83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.97      0.97      0.97      2544\n",
      "           B       0.94      0.92      0.93      3076\n",
      "           C       0.85      0.87      0.86      2148\n",
      "           D       0.80      0.80      0.80      1455\n",
      "           E       0.76      0.72      0.74       809\n",
      "           F       0.63      0.74      0.68       302\n",
      "           G       0.71      0.76      0.73       109\n",
      "\n",
      "    accuracy                           0.88     10443\n",
      "   macro avg       0.81      0.83      0.82     10443\n",
      "weighted avg       0.88      0.88      0.88     10443\n",
>>>>>>> main
      "\n"
     ]
    }
   ],
   "source": [
    "####fit von log reg\n",
    "\n",
    "lr = LogisticRegression(max_iter=10000, C = 2.0, random_state=70)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_grade_pred_lr_test = lr.predict(X_test)\n",
    "score_print(y_test,y_grade_pred_lr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[16045   259     0     0     0     0     0]\n",
      " [  291 15262   751     0     0     0     0]\n",
      " [    3   527 14795   979     0     0     0]\n",
      " [    4     1   861 13933  1505     0     0]\n",
      " [    5     2     5  1499 13221  1572     0]\n",
      " [    0     0     0     0  1735 12880  1689]\n",
      " [    0     0     0     0     0  1571 14733]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.98      0.98      0.98     16304\n",
      "           B       0.95      0.94      0.94     16304\n",
      "           C       0.90      0.91      0.90     16304\n",
      "           D       0.85      0.85      0.85     16304\n",
      "           E       0.80      0.81      0.81     16304\n",
      "           F       0.80      0.79      0.80     16304\n",
      "           G       0.90      0.90      0.90     16304\n",
      "\n",
      "    accuracy                           0.88    114128\n",
      "   macro avg       0.88      0.88      0.88    114128\n",
      "weighted avg       0.88      0.88      0.88    114128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########## score auf unsere trainingdaten\n",
    "y_grade_pred_lr_train = lr.predict(X_train)\n",
    "\n",
    "score_print(y_train,y_grade_pred_lr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Stored 'y_grade_pred_lr_train' (ndarray)\nStored 'y_grade_pred_lr_test' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "%store y_grade_pred_lr_train y_grade_pred_lr_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[2544    0    0    0    0    0    0]\n",
      " [   1 3072    2    0    1    0    0]\n",
      " [   0    4 2101   43    0    0    0]\n",
      " [   0    1   10 1437    7    0    0]\n",
      " [   0    1    0   44  758    6    0]\n",
      " [   0    0    0    0   11  278   13]\n",
      " [   0    0    0    0    0    8  101]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       1.00      1.00      1.00      2544\n",
      "           B       1.00      1.00      1.00      3076\n",
      "           C       0.99      0.98      0.99      2148\n",
      "           D       0.94      0.99      0.96      1455\n",
      "           E       0.98      0.94      0.96       809\n",
      "           F       0.95      0.92      0.94       302\n",
      "           G       0.89      0.93      0.91       109\n",
      "\n",
      "    accuracy                           0.99     10443\n",
      "   macro avg       0.96      0.96      0.96     10443\n",
      "weighted avg       0.99      0.99      0.99     10443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######## DecisionTree\n",
    "\n",
    "dtc = DecisionTreeClassifier(max_depth=10, min_samples_split=5, random_state=70)\n",
    "dtc.fit(X_train,y_train)\n",
    "y_grade_pred_dtc_test=dtc.predict(X_test)\n",
    "score_print(y_test,y_grade_pred_dtc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[16303     0     1     0     0     0     0]\n",
      " [    1 16268    34     1     0     0     0]\n",
      " [    0    76 15884   344     0     0     0]\n",
      " [    0     1   207 15644   452     0     0]\n",
      " [    0     2     5   702 15068   525     2]\n",
      " [    0     0     0     0   680 14923   701]\n",
      " [    0     0     0     0     0   534 15770]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       1.00      1.00      1.00     16304\n",
      "           B       1.00      1.00      1.00     16304\n",
      "           C       0.98      0.97      0.98     16304\n",
      "           D       0.94      0.96      0.95     16304\n",
      "           E       0.93      0.92      0.93     16304\n",
      "           F       0.93      0.92      0.92     16304\n",
      "           G       0.96      0.97      0.96     16304\n",
      "\n",
      "    accuracy                           0.96    114128\n",
      "   macro avg       0.96      0.96      0.96    114128\n",
      "weighted avg       0.96      0.96      0.96    114128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########## score auf unsere trainingdaten\n",
    "y_grade_pred_dtc_train = dtc.predict(X_train)\n",
    "score_print(y_train,y_grade_pred_dtc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Stored 'y_grade_pred_dtc_train' (ndarray)\nStored 'y_grade_pred_dtc_test' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "%store y_grade_pred_dtc_train y_grade_pred_dtc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[2487   57    0    0    0    0    0]\n",
      " [  70 2967   39    0    0    0    0]\n",
      " [   1  178 1795  161   12    1    0]\n",
      " [   2    9  268  932  241    3    0]\n",
      " [   1    0   38  225  491   48    6]\n",
      " [   0    0    4   30   57  180   31]\n",
      " [   0    0    0    3    4   10   92]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.97      0.98      0.97      2544\n",
      "           B       0.92      0.96      0.94      3076\n",
      "           C       0.84      0.84      0.84      2148\n",
      "           D       0.69      0.64      0.66      1455\n",
      "           E       0.61      0.61      0.61       809\n",
      "           F       0.74      0.60      0.66       302\n",
      "           G       0.71      0.84      0.77       109\n",
      "\n",
      "    accuracy                           0.86     10443\n",
      "   macro avg       0.78      0.78      0.78     10443\n",
      "weighted avg       0.85      0.86      0.85     10443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### RandomForestClassifier\n",
    "\n",
    "rfc= RandomForestClassifier(max_depth=10,min_samples_split=7)\n",
    "rfc.fit(X_train,y_train)\n",
    "y_grade_pred_rfc_test=rfc.predict(X_test)\n",
    "score_print(y_test,y_grade_pred_rfc_test)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 62,
=======
   "execution_count": 12,
>>>>>>> main
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "[[7961  143    0    0    0    0    0]\n",
      " [ 148 7585  382    0    0    0    0]\n",
      " [   2  269 7346  484    0    0    0]\n",
      " [   0    0  441 6916  746    0    0]\n",
      " [   0    1    0  689 6765  799    0]\n",
      " [   0    0    0    0  907 6369  783]\n",
      " [   0    0    0    0    0  639 7696]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.98      0.98      0.98      8104\n",
      "           B       0.95      0.93      0.94      8115\n",
      "           C       0.90      0.91      0.90      8101\n",
      "           D       0.85      0.85      0.85      8103\n",
      "           E       0.80      0.82      0.81      8254\n",
      "           F       0.82      0.79      0.80      8059\n",
      "           G       0.91      0.92      0.92      8335\n",
      "\n",
      "    accuracy                           0.89     57071\n",
      "   macro avg       0.89      0.89      0.89     57071\n",
      "weighted avg       0.89      0.89      0.89     57071\n",
=======
      "[[16140   164     0     0     0     0     0]\n",
      " [  236 15975    93     0     0     0     0]\n",
      " [    3   873 14600   757    66     5     0]\n",
      " [    4    58  1483 12533  2216     8     2]\n",
      " [    4     3   365  2619 12727   576    10]\n",
      " [    0     0   182   846  1285 13214   777]\n",
      " [    0     0    98   256    28   296 15626]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.98      0.99      0.99     16304\n",
      "           B       0.94      0.98      0.96     16304\n",
      "           C       0.87      0.90      0.88     16304\n",
      "           D       0.74      0.77      0.75     16304\n",
      "           E       0.78      0.78      0.78     16304\n",
      "           F       0.94      0.81      0.87     16304\n",
      "           G       0.95      0.96      0.96     16304\n",
      "\n",
      "    accuracy                           0.88    114128\n",
      "   macro avg       0.88      0.88      0.88    114128\n",
      "weighted avg       0.88      0.88      0.88    114128\n",
>>>>>>> main
      "\n"
     ]
    }
   ],
   "source": [
    "########## score auf unsere trainingdaten\n",
<<<<<<< HEAD
    "\n",
    "score_print(y_train,lr.predict(X_train))"
=======
    "y_grade_pred_rfc_train =rfc.predict(X_train)\n",
    "score_print(y_train,y_grade_pred_rfc_train)"
>>>>>>> main
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2542    3    0    0    0    0    0]\n",
      " [   1 3095    2    0    0    0    0]\n",
      " [   1    6 2129   50    0    0    0]\n",
      " [   2    0    9 1473   20    0    0]\n",
      " [   0    0    1   56  788    4    0]\n",
      " [   0    0    0    0   12  304    9]\n",
      " [   0    0    0    0    0   10  117]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       1.00      1.00      1.00      2545\n",
      "           B       1.00      1.00      1.00      3098\n",
      "           C       0.99      0.97      0.98      2186\n",
      "           D       0.93      0.98      0.96      1504\n",
      "           E       0.96      0.93      0.94       849\n",
      "           F       0.96      0.94      0.95       325\n",
      "           G       0.93      0.92      0.92       127\n",
      "\n",
      "    accuracy                           0.98     10634\n",
      "   macro avg       0.97      0.96      0.96     10634\n",
      "weighted avg       0.98      0.98      0.98     10634\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######## DecisionTree\n",
    "\n",
    "dtc = DecisionTreeClassifier(max_depth=10, min_samples_split=5, random_state=70)\n",
    "dtc.fit(X_train,y_train)\n",
    "y_pred_dtc=dtc.predict(X_test)\n",
    "score_print(y_test,y_pred_dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8104    0    0    0    0    0    0]\n",
      " [   4 8094   17    0    0    0    0]\n",
      " [   0   34 7828  239    0    0    0]\n",
      " [   0    0   76 7792  235    0    0]\n",
      " [   0    0    0  330 7577  347    0]\n",
      " [   0    0    0    0  309 7481  269]\n",
      " [   0    0    0    0    0  294 8041]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       1.00      1.00      1.00      8104\n",
      "           B       1.00      1.00      1.00      8115\n",
      "           C       0.99      0.97      0.98      8101\n",
      "           D       0.93      0.96      0.95      8103\n",
      "           E       0.93      0.92      0.93      8254\n",
      "           F       0.92      0.93      0.92      8059\n",
      "           G       0.97      0.96      0.97      8335\n",
      "\n",
      "    accuracy                           0.96     57071\n",
      "   macro avg       0.96      0.96      0.96     57071\n",
      "weighted avg       0.96      0.96      0.96     57071\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########## score auf unsere trainingdaten\n",
    " \n",
    "score_print(y_train,dtc.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2488   57    0    0    0    0    0]\n",
      " [  69 3009   20    0    0    0    0]\n",
      " [   1  179 1837  162    6    1    0]\n",
      " [   2    9  143 1093  251    6    0]\n",
      " [   1    0    7  205  584   50    2]\n",
      " [   0    0    0   18   44  219   44]\n",
      " [   0    0    0    4    3   15  105]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.97      0.98      0.97      2545\n",
      "           B       0.92      0.97      0.95      3098\n",
      "           C       0.92      0.84      0.88      2186\n",
      "           D       0.74      0.73      0.73      1504\n",
      "           E       0.66      0.69      0.67       849\n",
      "           F       0.75      0.67      0.71       325\n",
      "           G       0.70      0.83      0.76       127\n",
      "\n",
      "    accuracy                           0.88     10634\n",
      "   macro avg       0.81      0.81      0.81     10634\n",
      "weighted avg       0.88      0.88      0.88     10634\n",
      "\n"
=======
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Stored 'y_grade_pred_rfc_train' (ndarray)\nStored 'y_grade_pred_rfc_test' (ndarray)\n"
>>>>>>> main
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "##### RandomForestClassifier\n",
    "\n",
    "rfc= RandomForestClassifier(max_depth=10,min_samples_split=7)\n",
    "rfc.fit(X_train,y_train)\n",
    "y_pred_rfc=rfc.predict(X_test)\n",
    "score_print(y_test,y_pred_rfc)"
=======
    "%store y_grade_pred_rfc_train y_grade_pred_rfc_test"
>>>>>>> main
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8031   73    0    0    0    0    0]\n",
      " [ 101 8005    9    0    0    0    0]\n",
      " [   2  386 7271  432   10    0    0]\n",
      " [   0   15  424 6744  907   12    1]\n",
      " [   0    1   42 1209 6634  349   19]\n",
      " [   0    0   18  357  446 6839  399]\n",
      " [   0    0   11   97   57  197 7973]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.99      0.99      0.99      8104\n",
      "           B       0.94      0.99      0.96      8115\n",
      "           C       0.94      0.90      0.92      8101\n",
      "           D       0.76      0.83      0.80      8103\n",
      "           E       0.82      0.80      0.81      8254\n",
      "           F       0.92      0.85      0.88      8059\n",
      "           G       0.95      0.96      0.95      8335\n",
      "\n",
      "    accuracy                           0.90     57071\n",
      "   macro avg       0.90      0.90      0.90     57071\n",
      "weighted avg       0.90      0.90      0.90     57071\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########## score auf unsere trainingdaten\n",
    "\n",
    "score_print(y_train,rfc.predict(X_train))"
   ]
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
>>>>>>> main
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e14aed01f57e2f30c4ad33bfe147e3add576437b8baa5fa8c8b958544bcab44"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

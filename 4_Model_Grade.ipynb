{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('.venv': venv)"
  },
  "interpreter": {
   "hash": "1e14aed01f57e2f30c4ad33bfe147e3add576437b8baa5fa8c8b958544bcab44"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r X_train X_test y_grade_train y_grade_test\n",
    "\n",
    "y_train = y_grade_train\n",
    "y_test = y_grade_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Funktion to printe the scores\n",
    "def score_print(y,y_pred):\n",
    "    \n",
    "    cm = confusion_matrix(y,y_pred)\n",
    "    print(cm)\n",
    "    cp= classification_report(y,y_pred)\n",
    "    print(cp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      0\n",
       "G  8335\n",
       "E  8254\n",
       "B  8115\n",
       "A  8104\n",
       "D  8103\n",
       "C  8101\n",
       "F  8059"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>G</th>\n      <td>8335</td>\n    </tr>\n    <tr>\n      <th>E</th>\n      <td>8254</td>\n    </tr>\n    <tr>\n      <th>B</th>\n      <td>8115</td>\n    </tr>\n    <tr>\n      <th>A</th>\n      <td>8104</td>\n    </tr>\n    <tr>\n      <th>D</th>\n      <td>8103</td>\n    </tr>\n    <tr>\n      <th>C</th>\n      <td>8101</td>\n    </tr>\n    <tr>\n      <th>F</th>\n      <td>8059</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "grades = pd.DataFrame(y_train.value_counts())\n",
    "grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total number of records: 57071\nIndividuals have grades:       0\nG  8335\nE  8254\nB  8115\nA  8104\nD  8103\nC  8101\nF  8059\nIndividuals have most likely grade: G\nIndividuals have most likely grade with percent: 14.60%\n"
     ]
    }
   ],
   "source": [
    "###### Naiv-estimator\n",
    "\n",
    "# TODO: Total number of records\n",
    "n_records = len(y_train)\n",
    "\n",
    "# TODO: Different grades\n",
    "grades = pd.DataFrame(y_train.value_counts())\n",
    "\n",
    "# TODO: Mmost frequent grade \n",
    "most_frequent_grade = grades[grades[0] == int(grades.max())].index.tolist()[0]\n",
    "\n",
    "# TODO: Percentage of individuals whose income is more than $50,000\n",
    "percent = float(100 * grades.max() / n_records)\n",
    "\n",
    "# Print the results\n",
    "print (\"Total number of records: {}\".format(n_records))\n",
    "print (\"Individuals have grades: {}\".format(grades))\n",
    "print (\"Individuals have most likely grade: {}\".format(most_frequent_grade))\n",
    "print (\"Individuals have most likely grade with percent: {:.2f}%\".format(percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[2467   78    0    0    0    0    0]\n",
      " [  74 2842  182    0    0    0    0]\n",
      " [   1  114 1864  207    0    0    0]\n",
      " [   2    0  144 1180  178    0    0]\n",
      " [   1    0    0  113  638   97    0]\n",
      " [   0    0    0    0   46  241   38]\n",
      " [   0    0    0    0    0   22  105]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.97      0.97      0.97      2545\n",
      "           B       0.94      0.92      0.93      3098\n",
      "           C       0.85      0.85      0.85      2186\n",
      "           D       0.79      0.78      0.79      1504\n",
      "           E       0.74      0.75      0.75       849\n",
      "           F       0.67      0.74      0.70       325\n",
      "           G       0.73      0.83      0.78       127\n",
      "\n",
      "    accuracy                           0.88     10634\n",
      "   macro avg       0.81      0.83      0.82     10634\n",
      "weighted avg       0.88      0.88      0.88     10634\n",
      "\n"
     ]
    }
   ],
   "source": [
    "####fit von log reg\n",
    "\n",
    "lr = LogisticRegression(max_iter=10000, C = 2.0, random_state=70)\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "score_print(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[7961  143    0    0    0    0    0]\n",
      " [ 148 7585  382    0    0    0    0]\n",
      " [   2  269 7346  484    0    0    0]\n",
      " [   0    0  441 6916  746    0    0]\n",
      " [   0    1    0  689 6765  799    0]\n",
      " [   0    0    0    0  907 6369  783]\n",
      " [   0    0    0    0    0  639 7696]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.98      0.98      0.98      8104\n",
      "           B       0.95      0.93      0.94      8115\n",
      "           C       0.90      0.91      0.90      8101\n",
      "           D       0.85      0.85      0.85      8103\n",
      "           E       0.80      0.82      0.81      8254\n",
      "           F       0.82      0.79      0.80      8059\n",
      "           G       0.91      0.92      0.92      8335\n",
      "\n",
      "    accuracy                           0.89     57071\n",
      "   macro avg       0.89      0.89      0.89     57071\n",
      "weighted avg       0.89      0.89      0.89     57071\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########## score auf unsere trainingdaten\n",
    "\n",
    "score_print(y_train,lr.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[2542    3    0    0    0    0    0]\n [   1 3095    2    0    0    0    0]\n [   1    6 2129   50    0    0    0]\n [   2    0    9 1473   20    0    0]\n [   0    0    1   56  788    4    0]\n [   0    0    0    0   12  304    9]\n [   0    0    0    0    0   10  117]]\n              precision    recall  f1-score   support\n\n           A       1.00      1.00      1.00      2545\n           B       1.00      1.00      1.00      3098\n           C       0.99      0.97      0.98      2186\n           D       0.93      0.98      0.96      1504\n           E       0.96      0.93      0.94       849\n           F       0.96      0.94      0.95       325\n           G       0.93      0.92      0.92       127\n\n    accuracy                           0.98     10634\n   macro avg       0.97      0.96      0.96     10634\nweighted avg       0.98      0.98      0.98     10634\n\n"
     ]
    }
   ],
   "source": [
    "######## DecisionTree\n",
    "\n",
    "dtc = DecisionTreeClassifier(max_depth=10, min_samples_split=5, random_state=70)\n",
    "dtc.fit(X_train,y_train)\n",
    "y_pred_dtc=dtc.predict(X_test)\n",
    "score_print(y_test,y_pred_dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[8104    0    0    0    0    0    0]\n",
      " [   4 8094   17    0    0    0    0]\n",
      " [   0   34 7828  239    0    0    0]\n",
      " [   0    0   76 7792  235    0    0]\n",
      " [   0    0    0  330 7577  347    0]\n",
      " [   0    0    0    0  309 7481  269]\n",
      " [   0    0    0    0    0  294 8041]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       1.00      1.00      1.00      8104\n",
      "           B       1.00      1.00      1.00      8115\n",
      "           C       0.99      0.97      0.98      8101\n",
      "           D       0.93      0.96      0.95      8103\n",
      "           E       0.93      0.92      0.93      8254\n",
      "           F       0.92      0.93      0.92      8059\n",
      "           G       0.97      0.96      0.97      8335\n",
      "\n",
      "    accuracy                           0.96     57071\n",
      "   macro avg       0.96      0.96      0.96     57071\n",
      "weighted avg       0.96      0.96      0.96     57071\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########## score auf unsere trainingdaten\n",
    " \n",
    "score_print(y_train,dtc.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[2488   57    0    0    0    0    0]\n [  69 3009   20    0    0    0    0]\n [   1  179 1837  162    6    1    0]\n [   2    9  143 1093  251    6    0]\n [   1    0    7  205  584   50    2]\n [   0    0    0   18   44  219   44]\n [   0    0    0    4    3   15  105]]\n              precision    recall  f1-score   support\n\n           A       0.97      0.98      0.97      2545\n           B       0.92      0.97      0.95      3098\n           C       0.92      0.84      0.88      2186\n           D       0.74      0.73      0.73      1504\n           E       0.66      0.69      0.67       849\n           F       0.75      0.67      0.71       325\n           G       0.70      0.83      0.76       127\n\n    accuracy                           0.88     10634\n   macro avg       0.81      0.81      0.81     10634\nweighted avg       0.88      0.88      0.88     10634\n\n"
     ]
    }
   ],
   "source": [
    "##### RandomForestClassifier\n",
    "\n",
    "rfc= RandomForestClassifier(max_depth=10,min_samples_split=7)\n",
    "rfc.fit(X_train,y_train)\n",
    "y_pred_rfc=rfc.predict(X_test)\n",
    "score_print(y_test,y_pred_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[8031   73    0    0    0    0    0]\n",
      " [ 101 8005    9    0    0    0    0]\n",
      " [   2  386 7271  432   10    0    0]\n",
      " [   0   15  424 6744  907   12    1]\n",
      " [   0    1   42 1209 6634  349   19]\n",
      " [   0    0   18  357  446 6839  399]\n",
      " [   0    0   11   97   57  197 7973]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.99      0.99      0.99      8104\n",
      "           B       0.94      0.99      0.96      8115\n",
      "           C       0.94      0.90      0.92      8101\n",
      "           D       0.76      0.83      0.80      8103\n",
      "           E       0.82      0.80      0.81      8254\n",
      "           F       0.92      0.85      0.88      8059\n",
      "           G       0.95      0.96      0.95      8335\n",
      "\n",
      "    accuracy                           0.90     57071\n",
      "   macro avg       0.90      0.90      0.90     57071\n",
      "weighted avg       0.90      0.90      0.90     57071\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########## score auf unsere trainingdaten\n",
    "\n",
    "score_print(y_train,rfc.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
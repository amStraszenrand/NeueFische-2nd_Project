{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('.venv': venv)"
  },
  "interpreter": {
   "hash": "1e14aed01f57e2f30c4ad33bfe147e3add576437b8baa5fa8c8b958544bcab44"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r X_train X_test y_grade_train y_grade_test\n",
    "\n",
    "y_train = y_grade_train\n",
    "y_test = y_grade_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, classification_report, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Funktion to printe the scores\n",
    "def score_print(y,y_pred):\n",
    "    \n",
    "    cm = confusion_matrix(y,y_pred)\n",
    "    print(cm)\n",
    "    cp= classification_report(y,y_pred)\n",
    "    print(cp)\n",
    "    #roc = roc_auc_score(y, y_pred)\n",
    "    #print(roc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total number of records: 114128\nIndividuals have grades:        0\nF  16304\nB  16304\nD  16304\nA  16304\nE  16304\nG  16304\nC  16304\nIndividuals have most likely grade: F\nIndividuals have most likely grade with percent: 14.29%\n"
     ]
    }
   ],
   "source": [
    "###### Naiv-estimator\n",
    "\n",
    "# TODO: Total number of records\n",
    "n_records = len(y_train)\n",
    "\n",
    "# TODO: Different grades\n",
    "grades = pd.DataFrame(y_train.value_counts())\n",
    "\n",
    "# TODO: Mmost frequent grade \n",
    "most_frequent_grade = grades[grades[0] == int(grades.max())].index.tolist()[0]\n",
    "\n",
    "# TODO: Percentage of individuals whose income is more than $50,000\n",
    "percent = float(100 * grades.max() / n_records)\n",
    "\n",
    "# Print the results\n",
    "print (\"Total number of records: {}\".format(n_records))\n",
    "print (\"Individuals have grades: {}\".format(grades))\n",
    "print (\"Individuals have most likely grade: {}\".format(most_frequent_grade))\n",
    "print (\"Individuals have most likely grade with percent: {:.2f}%\".format(percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[2476   69    0    0    0    0    0]\n",
      " [  71 2843  182    0    0    0    0]\n",
      " [   0  102 1884  197    0    0    0]\n",
      " [   2    0  143 1200  158    0    0]\n",
      " [   0    0    0  129  608  111    0]\n",
      " [   0    0    0    0   46  235   44]\n",
      " [   0    0    0    0    0   20  107]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.97      0.97      0.97      2545\n",
      "           B       0.94      0.92      0.93      3096\n",
      "           C       0.85      0.86      0.86      2183\n",
      "           D       0.79      0.80      0.79      1503\n",
      "           E       0.75      0.72      0.73       848\n",
      "           F       0.64      0.72      0.68       325\n",
      "           G       0.71      0.84      0.77       127\n",
      "\n",
      "    accuracy                           0.88     10627\n",
      "   macro avg       0.81      0.83      0.82     10627\n",
      "weighted avg       0.88      0.88      0.88     10627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "####fit von log reg\n",
    "\n",
    "lr = LogisticRegression(max_iter=10000, C = 2.0, random_state=70)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_grade_pred_lr_test = lr.predict(X_test)\n",
    "score_print(y_test,y_grade_pred_lr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[15990   314     0     0     0     0     0]\n",
      " [  299 15165   840     0     0     0     0]\n",
      " [    4   594 14749   957     0     0     0]\n",
      " [    2     1   861 14107  1333     0     0]\n",
      " [   15    12     6  1307 13492  1472     0]\n",
      " [    0     0     0     0  1624 13275  1405]\n",
      " [    0     0     0     0     0  1414 14890]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.98      0.98      0.98     16304\n",
      "           B       0.94      0.93      0.94     16304\n",
      "           C       0.90      0.90      0.90     16304\n",
      "           D       0.86      0.87      0.86     16304\n",
      "           E       0.82      0.83      0.82     16304\n",
      "           F       0.82      0.81      0.82     16304\n",
      "           G       0.91      0.91      0.91     16304\n",
      "\n",
      "    accuracy                           0.89    114128\n",
      "   macro avg       0.89      0.89      0.89    114128\n",
      "weighted avg       0.89      0.89      0.89    114128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########## score auf unsere trainingdaten\n",
    "y_grade_pred_lr_train = lr.predict(X_train)\n",
    "\n",
    "score_print(y_train,y_grade_pred_lr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Stored 'y_grade_pred_lr_train' (ndarray)\nStored 'y_grade_pred_lr_test' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "%store y_grade_pred_lr_train y_grade_pred_lr_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[2541    2    0    0    2    0    0]\n [   0 3093    3    0    0    0    0]\n [   0    5 2170    8    0    0    0]\n [   0    1    9 1476   14    3    0]\n [   0    0    0   48  774   26    0]\n [   0    0    0    0   10  298   17]\n [   0    0    0    0    0   11  116]]\n              precision    recall  f1-score   support\n\n           A       1.00      1.00      1.00      2545\n           B       1.00      1.00      1.00      3096\n           C       0.99      0.99      0.99      2183\n           D       0.96      0.98      0.97      1503\n           E       0.97      0.91      0.94       848\n           F       0.88      0.92      0.90       325\n           G       0.87      0.91      0.89       127\n\n    accuracy                           0.99     10627\n   macro avg       0.95      0.96      0.96     10627\nweighted avg       0.99      0.99      0.99     10627\n\n"
     ]
    }
   ],
   "source": [
    "######## DecisionTree\n",
    "\n",
    "dtc = DecisionTreeClassifier(max_depth=10, min_samples_split=5, random_state=70)\n",
    "dtc.fit(X_train,y_train)\n",
    "y_grade_pred_dtc_test=dtc.predict(X_test)\n",
    "score_print(y_test,y_grade_pred_dtc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[16306     0     0     0     0     0     0]\n",
      " [    1 16274    31     0     0     0     0]\n",
      " [    1    63 15818   424     0     0     0]\n",
      " [    1     1   178 15548   578     0     0]\n",
      " [    1     3     1   605 15084   612     0]\n",
      " [    0     0     0     0   762 14885   659]\n",
      " [    0     0     0     0     0   531 15775]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       1.00      1.00      1.00     16306\n",
      "           B       1.00      1.00      1.00     16306\n",
      "           C       0.99      0.97      0.98     16306\n",
      "           D       0.94      0.95      0.95     16306\n",
      "           E       0.92      0.93      0.92     16306\n",
      "           F       0.93      0.91      0.92     16306\n",
      "           G       0.96      0.97      0.96     16306\n",
      "\n",
      "    accuracy                           0.96    114142\n",
      "   macro avg       0.96      0.96      0.96    114142\n",
      "weighted avg       0.96      0.96      0.96    114142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########## score auf unsere trainingdaten\n",
    "y_grade_pred_dtc_train = dtc.predict(X_train)\n",
    "score_print(y_train,y_grade_pred_dtc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Stored 'y_grade_pred_dtc_train' (ndarray)\nStored 'y_grade_pred_dtc_test' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "%store y_grade_pred_dtc_train y_grade_pred_dtc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[2491   54    0    0    0    0    0]\n",
      " [  63 2998   37    0    0    0    0]\n",
      " [   1  168 1838  178    1    0    0]\n",
      " [   2    8  143 1177  166    5    3]\n",
      " [   1    0   11  214  558   57    8]\n",
      " [   0    0    0   18   43  224   40]\n",
      " [   0    0    0    4    4   19  100]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.97      0.98      0.98      2545\n",
      "           B       0.93      0.97      0.95      3098\n",
      "           C       0.91      0.84      0.87      2186\n",
      "           D       0.74      0.78      0.76      1504\n",
      "           E       0.72      0.66      0.69       849\n",
      "           F       0.73      0.69      0.71       325\n",
      "           G       0.66      0.79      0.72       127\n",
      "\n",
      "    accuracy                           0.88     10634\n",
      "   macro avg       0.81      0.81      0.81     10634\n",
      "weighted avg       0.88      0.88      0.88     10634\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### RandomForestClassifier\n",
    "\n",
    "rfc= RandomForestClassifier(max_depth=10,min_samples_split=7)\n",
    "rfc.fit(X_train,y_train)\n",
    "y_grade_pred_rfc_test=rfc.predict(X_test)\n",
    "score_print(y_test,y_grade_pred_rfc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[16137   169     0     0     0     0     0]\n",
      " [  200 16051    55     0     0     0     0]\n",
      " [    4   788 14429  1074    10     1     0]\n",
      " [    3    25   965 14112  1184    16     1]\n",
      " [    9     3    86  2696 12688   769    55]\n",
      " [    0     0    22   822   935 13623   904]\n",
      " [    0     0    12   233   162   475 15424]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.99      0.99      0.99     16306\n",
      "           B       0.94      0.98      0.96     16306\n",
      "           C       0.93      0.88      0.91     16306\n",
      "           D       0.75      0.87      0.80     16306\n",
      "           E       0.85      0.78      0.81     16306\n",
      "           F       0.92      0.84      0.87     16306\n",
      "           G       0.94      0.95      0.94     16306\n",
      "\n",
      "    accuracy                           0.90    114142\n",
      "   macro avg       0.90      0.90      0.90    114142\n",
      "weighted avg       0.90      0.90      0.90    114142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########## score auf unsere trainingdaten\n",
    "y_grade_pred_rfc_train =rfc.predict(X_train)\n",
    "score_print(y_train,y_grade_pred_rfc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Stored 'y_grade_pred_rfc_train' (ndarray)\nStored 'y_grade_pred_rfc_test' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "%store y_grade_pred_rfc_train y_grade_pred_rfc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
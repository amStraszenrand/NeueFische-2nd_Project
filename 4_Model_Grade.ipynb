{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('.venv': venv)"
  },
  "interpreter": {
   "hash": "1e14aed01f57e2f30c4ad33bfe147e3add576437b8baa5fa8c8b958544bcab44"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r X_train X_test y_grade_train y_grade_test\n",
    "\n",
    "y_train = y_grade_train\n",
    "y_test = y_grade_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, classification_report, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Funktion to printe the scores\n",
    "def score_print(y,y_pred):\n",
    "    \n",
    "    cm = confusion_matrix(y,y_pred)\n",
    "    print(cm)\n",
    "    cp= classification_report(y,y_pred)\n",
    "    print(cp)\n",
    "    #roc = roc_auc_score(y, y_pred)\n",
    "    #print(roc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total number of records: 114128\nIndividuals have grades:        0\nA  16304\nD  16304\nC  16304\nE  16304\nF  16304\nB  16304\nG  16304\nIndividuals have most likely grade: A\nIndividuals have most likely grade with percent: 14.29%\n"
     ]
    }
   ],
   "source": [
    "###### Naiv-estimator\n",
    "\n",
    "# TODO: Total number of records\n",
    "n_records = len(y_train)\n",
    "\n",
    "# TODO: Different grades\n",
    "grades = pd.DataFrame(y_train.value_counts())\n",
    "\n",
    "# TODO: Mmost frequent grade \n",
    "most_frequent_grade = grades[grades[0] == int(grades.max())].index.tolist()[0]\n",
    "\n",
    "# TODO: Percentage of individuals whose income is more than $50,000\n",
    "percent = float(100 * grades.max() / n_records)\n",
    "\n",
    "# Print the results\n",
    "print (\"Total number of records: {}\".format(n_records))\n",
    "print (\"Individuals have grades: {}\".format(grades))\n",
    "print (\"Individuals have most likely grade: {}\".format(most_frequent_grade))\n",
    "print (\"Individuals have most likely grade with percent: {:.2f}%\".format(percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[2475   69    0    0    0    0    0]\n",
      " [  76 2821  179    0    0    0    0]\n",
      " [   1  104 1860  183    0    0    0]\n",
      " [   2    0  145 1165  143    0    0]\n",
      " [   1    0    0  117  584  107    0]\n",
      " [   0    0    0    0   45  223   34]\n",
      " [   0    0    0    0    0   26   83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.97      0.97      0.97      2544\n",
      "           B       0.94      0.92      0.93      3076\n",
      "           C       0.85      0.87      0.86      2148\n",
      "           D       0.80      0.80      0.80      1455\n",
      "           E       0.76      0.72      0.74       809\n",
      "           F       0.63      0.74      0.68       302\n",
      "           G       0.71      0.76      0.73       109\n",
      "\n",
      "    accuracy                           0.88     10443\n",
      "   macro avg       0.81      0.83      0.82     10443\n",
      "weighted avg       0.88      0.88      0.88     10443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "####fit von log reg\n",
    "\n",
    "lr = LogisticRegression(max_iter=10000, C = 2.0, random_state=70)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "y_grade_pred_lr_test = lr.predict(X_test)\n",
    "score_print(y_test,y_grade_pred_lr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[16045   259     0     0     0     0     0]\n",
      " [  291 15262   751     0     0     0     0]\n",
      " [    3   527 14795   979     0     0     0]\n",
      " [    4     1   861 13933  1505     0     0]\n",
      " [    5     2     5  1499 13221  1572     0]\n",
      " [    0     0     0     0  1735 12880  1689]\n",
      " [    0     0     0     0     0  1571 14733]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.98      0.98      0.98     16304\n",
      "           B       0.95      0.94      0.94     16304\n",
      "           C       0.90      0.91      0.90     16304\n",
      "           D       0.85      0.85      0.85     16304\n",
      "           E       0.80      0.81      0.81     16304\n",
      "           F       0.80      0.79      0.80     16304\n",
      "           G       0.90      0.90      0.90     16304\n",
      "\n",
      "    accuracy                           0.88    114128\n",
      "   macro avg       0.88      0.88      0.88    114128\n",
      "weighted avg       0.88      0.88      0.88    114128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########## score auf unsere trainingdaten\n",
    "y_grade_pred_lr_train = lr.predict(X_train)\n",
    "\n",
    "score_print(y_train,y_grade_pred_lr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Stored 'y_grade_pred_lr_train' (ndarray)\nStored 'y_grade_pred_lr_test' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "%store y_grade_pred_lr_train y_grade_pred_lr_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[2544    0    0    0    0    0    0]\n",
      " [   1 3072    2    0    1    0    0]\n",
      " [   0    4 2101   43    0    0    0]\n",
      " [   0    1   10 1437    7    0    0]\n",
      " [   0    1    0   44  758    6    0]\n",
      " [   0    0    0    0   11  278   13]\n",
      " [   0    0    0    0    0    8  101]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       1.00      1.00      1.00      2544\n",
      "           B       1.00      1.00      1.00      3076\n",
      "           C       0.99      0.98      0.99      2148\n",
      "           D       0.94      0.99      0.96      1455\n",
      "           E       0.98      0.94      0.96       809\n",
      "           F       0.95      0.92      0.94       302\n",
      "           G       0.89      0.93      0.91       109\n",
      "\n",
      "    accuracy                           0.99     10443\n",
      "   macro avg       0.96      0.96      0.96     10443\n",
      "weighted avg       0.99      0.99      0.99     10443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######## DecisionTree\n",
    "\n",
    "dtc = DecisionTreeClassifier(max_depth=10, min_samples_split=5, random_state=70)\n",
    "dtc.fit(X_train,y_train)\n",
    "y_grade_pred_dtc_test=dtc.predict(X_test)\n",
    "score_print(y_test,y_grade_pred_dtc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[16303     0     1     0     0     0     0]\n",
      " [    1 16268    34     1     0     0     0]\n",
      " [    0    76 15884   344     0     0     0]\n",
      " [    0     1   207 15644   452     0     0]\n",
      " [    0     2     5   702 15068   525     2]\n",
      " [    0     0     0     0   680 14923   701]\n",
      " [    0     0     0     0     0   534 15770]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       1.00      1.00      1.00     16304\n",
      "           B       1.00      1.00      1.00     16304\n",
      "           C       0.98      0.97      0.98     16304\n",
      "           D       0.94      0.96      0.95     16304\n",
      "           E       0.93      0.92      0.93     16304\n",
      "           F       0.93      0.92      0.92     16304\n",
      "           G       0.96      0.97      0.96     16304\n",
      "\n",
      "    accuracy                           0.96    114128\n",
      "   macro avg       0.96      0.96      0.96    114128\n",
      "weighted avg       0.96      0.96      0.96    114128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########## score auf unsere trainingdaten\n",
    "y_grade_pred_dtc_train = dtc.predict(X_train)\n",
    "score_print(y_train,y_grade_pred_dtc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Stored 'y_grade_pred_dtc_train' (ndarray)\nStored 'y_grade_pred_dtc_test' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "%store y_grade_pred_dtc_train y_grade_pred_dtc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[2487   57    0    0    0    0    0]\n",
      " [  70 2967   39    0    0    0    0]\n",
      " [   1  178 1795  161   12    1    0]\n",
      " [   2    9  268  932  241    3    0]\n",
      " [   1    0   38  225  491   48    6]\n",
      " [   0    0    4   30   57  180   31]\n",
      " [   0    0    0    3    4   10   92]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.97      0.98      0.97      2544\n",
      "           B       0.92      0.96      0.94      3076\n",
      "           C       0.84      0.84      0.84      2148\n",
      "           D       0.69      0.64      0.66      1455\n",
      "           E       0.61      0.61      0.61       809\n",
      "           F       0.74      0.60      0.66       302\n",
      "           G       0.71      0.84      0.77       109\n",
      "\n",
      "    accuracy                           0.86     10443\n",
      "   macro avg       0.78      0.78      0.78     10443\n",
      "weighted avg       0.85      0.86      0.85     10443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### RandomForestClassifier\n",
    "\n",
    "rfc= RandomForestClassifier(max_depth=10,min_samples_split=7)\n",
    "rfc.fit(X_train,y_train)\n",
    "y_grade_pred_rfc_test=rfc.predict(X_test)\n",
    "score_print(y_test,y_grade_pred_rfc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[16140   164     0     0     0     0     0]\n",
      " [  236 15975    93     0     0     0     0]\n",
      " [    3   873 14600   757    66     5     0]\n",
      " [    4    58  1483 12533  2216     8     2]\n",
      " [    4     3   365  2619 12727   576    10]\n",
      " [    0     0   182   846  1285 13214   777]\n",
      " [    0     0    98   256    28   296 15626]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.98      0.99      0.99     16304\n",
      "           B       0.94      0.98      0.96     16304\n",
      "           C       0.87      0.90      0.88     16304\n",
      "           D       0.74      0.77      0.75     16304\n",
      "           E       0.78      0.78      0.78     16304\n",
      "           F       0.94      0.81      0.87     16304\n",
      "           G       0.95      0.96      0.96     16304\n",
      "\n",
      "    accuracy                           0.88    114128\n",
      "   macro avg       0.88      0.88      0.88    114128\n",
      "weighted avg       0.88      0.88      0.88    114128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "########## score auf unsere trainingdaten\n",
    "y_grade_pred_rfc_train =rfc.predict(X_train)\n",
    "score_print(y_train,y_grade_pred_rfc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Stored 'y_grade_pred_rfc_train' (ndarray)\nStored 'y_grade_pred_rfc_test' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "%store y_grade_pred_rfc_train y_grade_pred_rfc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
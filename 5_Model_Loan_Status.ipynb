{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('.venv': venv)"
  },
  "interpreter": {
   "hash": "f65652939e43b240251679cd6b44d012c40ee3e672c80ac5c3588dc23d5ebd80"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r X_train X_test y_loan_status_train y_loan_status_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, classification_report, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Funktion to printe the scores\n",
    "def score_print(y,y_pred):\n",
    "    \n",
    "    cm = confusion_matrix(y,y_pred)\n",
    "    print(cm)\n",
    "    cp= classification_report(y,y_pred)\n",
    "    print(cp)\n",
    "    roc = roc_auc_score(y, y_pred)\n",
    "    print(roc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Total number of records: 55513\nIndividuals with Charged Off: 27832\nIndividuals percent of Charged Off: 50.14%\n"
     ]
    }
   ],
   "source": [
    "###### Naiv-estimator\n",
    "\n",
    "# TODO: Total number of records\n",
    "n_records = len(y_train)\n",
    "\n",
    "# TODO: People with Charged off\n",
    "charged_off = sum(y_train == 1)\n",
    "\n",
    "# TODO: Percentage of individuals with Charged Off\n",
    "percent = float(100 * charged_off / n_records)\n",
    "\n",
    "# Print the results\n",
    "print (\"Total number of records: {}\".format(n_records))\n",
    "print (\"Individuals with Charged Off: {}\".format(charged_off))\n",
    "print (\"Individuals percent of Charged Off: {:.2f}%\".format(percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[6157 2631]\n [1006  601]]\n              precision    recall  f1-score   support\n\n           0       0.86      0.70      0.77      8788\n           1       0.19      0.37      0.25      1607\n\n    accuracy                           0.65     10395\n   macro avg       0.52      0.54      0.51     10395\nweighted avg       0.76      0.65      0.69     10395\n\n0.5373016366437346\n"
     ]
    }
   ],
   "source": [
    "####fit von log reg\n",
    "\n",
    "lr = LogisticRegression(max_iter=10000, C = 2.0, random_state=70)\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "score_print(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[17159 10522]\n [10656 17176]]\n              precision    recall  f1-score   support\n\n           0       0.62      0.62      0.62     27681\n           1       0.62      0.62      0.62     27832\n\n    accuracy                           0.62     55513\n   macro avg       0.62      0.62      0.62     55513\nweighted avg       0.62      0.62      0.62     55513\n\n0.6185075171544111\n"
     ]
    }
   ],
   "source": [
    "########## score auf unsere trainingdaten\n",
    "\n",
    "score_print(y_train,lr.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r y_grade_pred_lr_train y_grade_pred_lr_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Item wrong length 114142 instead of 55513.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-e9098d8db44c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmask_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_grade_pred_lr_test\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mgrade\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mX_train_masked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_masked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mX_test_masked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_masked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neuefische/14_Second_Project/NeueFische-2nd_Project/.venv/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3013\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3015\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3017\u001b[0m         \u001b[0;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neuefische/14_Second_Project/NeueFische-2nd_Project/.venv/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3060\u001b[0m             )\n\u001b[1;32m   3061\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3062\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   3063\u001b[0m                 \u001b[0;34mf\"Item wrong length {len(key)} instead of {len(self.index)}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3064\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: Item wrong length 114142 instead of 55513."
     ]
    }
   ],
   "source": [
    "for grade in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]:\n",
    "#for grade in [\"A\", \"B\"]:\n",
    "    mask_train = y_grade_pred_lr_train == grade\n",
    "    mask_test = y_grade_pred_lr_test == grade\n",
    "\n",
    "    X_train_masked, y_train_masked = X_train[mask_train], y_train[mask_train]\n",
    "    X_test_masked, y_test_masked = X_test[mask_test], y_test[mask_test]\n",
    "\n",
    "    lr.fit(X_train_masked, y_train_masked)\n",
    "    lr.score(X_train_masked, y_train_masked)\n",
    "\n",
    "    y_loan_status_pred_lr_test = lr.predict(X_test_masked)\n",
    "    score_print(y_test_masked,y_loan_status_pred_lr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[5610 3178]\n [ 819  788]]\n              precision    recall  f1-score   support\n\n           0       0.87      0.64      0.74      8788\n           1       0.20      0.49      0.28      1607\n\n    accuracy                           0.62     10395\n   macro avg       0.54      0.56      0.51     10395\nweighted avg       0.77      0.62      0.67     10395\n\n0.5643626017149029\n"
     ]
    }
   ],
   "source": [
    "######## DecisionTree\n",
    "\n",
    "dtc = DecisionTreeClassifier(max_depth=10, min_samples_split=5, random_state=70)\n",
    "dtc.fit(X_train,y_train)\n",
    "y_pred_dtc=dtc.predict(X_test)\n",
    "score_print(y_test,y_pred_dtc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[17303 10378]\n [ 6988 20844]]\n              precision    recall  f1-score   support\n\n           0       0.71      0.63      0.67     27681\n           1       0.67      0.75      0.71     27832\n\n    accuracy                           0.69     55513\n   macro avg       0.69      0.69      0.69     55513\nweighted avg       0.69      0.69      0.69     55513\n\n0.6870039514881691\n"
     ]
    }
   ],
   "source": [
    "########## score auf unsere trainingdaten\n",
    " \n",
    "score_print(y_train,dtc.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r y_grade_pred_dtc_train y_grade_pred_dtc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Item wrong length 114142 instead of 55513.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-4b8525eab609>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmask_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_grade_pred_lr_test\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mgrade\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mX_train_masked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_masked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mX_test_masked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_masked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neuefische/14_Second_Project/NeueFische-2nd_Project/.venv/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3013\u001b[0m         \u001b[0;31m# Do we have a (boolean) 1d indexer?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3015\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_bool_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3017\u001b[0m         \u001b[0;31m# We are left with two options: a single key, and a collection of keys,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/neuefische/14_Second_Project/NeueFische-2nd_Project/.venv/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_bool_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3060\u001b[0m             )\n\u001b[1;32m   3061\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3062\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m   3063\u001b[0m                 \u001b[0;34mf\"Item wrong length {len(key)} instead of {len(self.index)}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3064\u001b[0m             )\n",
      "\u001b[0;31mValueError\u001b[0m: Item wrong length 114142 instead of 55513."
     ]
    }
   ],
   "source": [
    "for grade in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]:\n",
    "#for grade in [\"A\", \"B\"]:\n",
    "    mask_train = y_grade_pred_lr_train == grade\n",
    "    mask_test = y_grade_pred_lr_test == grade\n",
    "\n",
    "    X_train_masked, y_train_masked = X_train[mask_train], y_train[mask_train]\n",
    "    X_test_masked, y_test_masked = X_test[mask_test], y_test[mask_test]\n",
    "\n",
    "    dtc.fit(X_train_masked, y_train_masked)\n",
    "\n",
    "    y_loan_status_pred_dtc_test = dtc.predict(X_test_masked)\n",
    "    score_print(y_test_masked,y_loan_status_pred_dtc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[6513 2275]\n [ 912  695]]\n              precision    recall  f1-score   support\n\n           0       0.88      0.74      0.80      8788\n           1       0.23      0.43      0.30      1607\n\n    accuracy                           0.69     10395\n   macro avg       0.56      0.59      0.55     10395\nweighted avg       0.78      0.69      0.73     10395\n\n0.5868035738613978\n"
     ]
    }
   ],
   "source": [
    "##### RandomForestClassifier\n",
    "\n",
    "rfc= RandomForestClassifier(max_depth=10,min_samples_split=7)\n",
    "rfc.fit(X_train,y_train)\n",
    "y_pred_rfc=rfc.predict(X_test)\n",
    "score_print(y_test,y_pred_rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[19938  7743]\n [ 6706 21126]]\n              precision    recall  f1-score   support\n\n           0       0.75      0.72      0.73     27681\n           1       0.73      0.76      0.75     27832\n\n    accuracy                           0.74     55513\n   macro avg       0.74      0.74      0.74     55513\nweighted avg       0.74      0.74      0.74     55513\n\n0.7396658862898862\n"
     ]
    }
   ],
   "source": [
    "########## score auf unsere trainingdaten\n",
    "\n",
    "score_print(y_train,rfc.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r y_grade_pred_rfc_train y_grade_pred_rfc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1942  447]\n",
      " [ 104   49]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.81      0.88      2389\n",
      "           1       0.10      0.32      0.15       153\n",
      "\n",
      "    accuracy                           0.78      2542\n",
      "   macro avg       0.52      0.57      0.51      2542\n",
      "weighted avg       0.90      0.78      0.83      2542\n",
      "\n",
      "0.5665769307583504\n",
      "[[1908  741]\n",
      " [ 223  156]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.72      0.80      2649\n",
      "           1       0.17      0.41      0.24       379\n",
      "\n",
      "    accuracy                           0.68      3028\n",
      "   macro avg       0.53      0.57      0.52      3028\n",
      "weighted avg       0.81      0.68      0.73      3028\n",
      "\n",
      "0.5659406496801201\n",
      "[[1400  417]\n",
      " [ 276  101]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.77      0.80      1817\n",
      "           1       0.19      0.27      0.23       377\n",
      "\n",
      "    accuracy                           0.68      2194\n",
      "   macro avg       0.52      0.52      0.51      2194\n",
      "weighted avg       0.73      0.68      0.70      2194\n",
      "\n",
      "0.5192026674102093\n",
      "[[904 312]\n",
      " [192 120]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.74      0.78      1216\n",
      "           1       0.28      0.38      0.32       312\n",
      "\n",
      "    accuracy                           0.67      1528\n",
      "   macro avg       0.55      0.56      0.55      1528\n",
      "weighted avg       0.71      0.67      0.69      1528\n",
      "\n",
      "0.5640182186234818\n",
      "[[439 180]\n",
      " [142  72]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.71      0.73       619\n",
      "           1       0.29      0.34      0.31       214\n",
      "\n",
      "    accuracy                           0.61       833\n",
      "   macro avg       0.52      0.52      0.52       833\n",
      "weighted avg       0.63      0.61      0.62       833\n",
      "\n",
      "0.5228284993885224\n",
      "[[163  88]\n",
      " [ 64  51]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.65      0.68       251\n",
      "           1       0.37      0.44      0.40       115\n",
      "\n",
      "    accuracy                           0.58       366\n",
      "   macro avg       0.54      0.55      0.54       366\n",
      "weighted avg       0.61      0.58      0.59       366\n",
      "\n",
      "0.5464403256539061\n",
      "[[49 39]\n",
      " [24 31]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.56      0.61        88\n",
      "           1       0.44      0.56      0.50        55\n",
      "\n",
      "    accuracy                           0.56       143\n",
      "   macro avg       0.56      0.56      0.55       143\n",
      "weighted avg       0.58      0.56      0.57       143\n",
      "\n",
      "0.5602272727272727\n"
     ]
    }
   ],
   "source": [
    "for grade in [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]:\n",
    "#for grade in [\"A\", \"B\"]:\n",
    "    mask_train = y_grade_pred_lr_train == grade\n",
    "    mask_test = y_grade_pred_lr_test == grade\n",
    "\n",
    "    X_train_masked, y_train_masked = X_train[mask_train], y_train[mask_train]\n",
    "    X_test_masked, y_test_masked = X_test[mask_test], y_test[mask_test]\n",
    "\n",
    "    rfc.fit(X_train_masked, y_train_masked)\n",
    "\n",
    "    y_loan_status_pred_rfc_test = rfc.predict(X_test_masked)\n",
    "    score_print(y_test_masked,y_loan_status_pred_rfc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
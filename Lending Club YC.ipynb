{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43adb1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import sweetviz as vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "317b362d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Unknown variable 'df'\n"
     ]
    }
   ],
   "source": [
    "%store df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f35d489",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compl = pd.read_csv(\"Lending Club/loans_2007.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b20715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compl.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e9e948",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compl.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f203b3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wir elimierniern drei übeltäter die voll mit nans sind in der zeile\n",
    "rows_delete=df_compl[df_compl[\"loan_amnt\"].isnull()].index\n",
    "\n",
    "\n",
    "df_compl= df_compl.drop(rows_delete, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4889993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################### Data cleaning\n",
    "# emp_legth,home_ownership verdummien\n",
    "# interaktionterm von annual income und verifications_status\n",
    "# untersuchen ob zwischen 2007 und 2009 kreditausfälle stattgefunden haben durch die krise, varibale issue_d untersuchen\n",
    "# loan_status zu einer neuen kategorievariable machen mit : 0 = gezahlt, 1= ausstehend, 2= nicht in der lage\n",
    "# die, die wir rausgeschmissen haben, haben wir entweder nicht verstanden oder waren unbalancierte variablen \n",
    "# emp_length verdummien, da ca. 1100 fehlen\n",
    "\n",
    "\n",
    "columns_delete=[\"id\", \"member_id\", \"grade\", \"emp_title\",\"pymnt_plan\",\"title\",\"zip_code\", \"addr_state\",\"delinq_2yrs\",\"earliest_cr_line\",\"inq_last_6mths\",\"pub_rec\",\"revol_util\",\"total_acc\",\"initial_list_status\",\"out_prncp\",\"out_prncp_inv\",\"total_pymnt\",\"last_pymnt_amnt\",\"last_pymnt_d\",\"last_credit_pull_d\",\"collections_12_mths_ex_med\",\"policy_code\",\"application_type\",\"acc_now_delinq\",\"chargeoff_within_12_mths\",\"delinq_amnt\",\"tax_liens\"]\n",
    "\n",
    "y_columns=[\"loan_status\",\"sub_grade\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cdfc5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a28925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier wird das y, also unser target bestimmt\n",
    "y_columns=[\"loan_status\",\"sub_grade\"]\n",
    "y_target=df_compl[y_columns]\n",
    "\n",
    "y_app= y_target[\"loan_status\"].apply(lambda y: 1 if y == y_01[0] else 0)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb93d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_compl.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b004b646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weitere features werden gelöscht aufgrund correlations\n",
    "columns_corr=[\"funded_amnt\",\"funded_amnt_inv\",\"total_pymnt_inv\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8831da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weitere features werden gelöscht, da sie die selben infos tragen bzw. daraus werden unsere anderen variablen bestimmt\n",
    "columns_sameinfo=[\"total_rec_int\",\"total_rec_prncp\",\"total_rec_late_fee\", \"recoveries\",\"collection_recovery_fee\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5748670f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spalten löschen\n",
    "df= df_compl.drop(columns_delete, axis=1).drop(y_colmuns, axis=1).drop(columns_corr, axis=1).drop(columns_sameinfo, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d53f394",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Hier werden die dateintypen, welche falsch sind korrigiert\n",
    "if type(df[\"int_rate\"][0])== type(\"str\"): \n",
    "    df[\"int_rate\"]=df[\"int_rate\"].str.strip(\"%\").astype(\"float\")\n",
    "else:\n",
    "    print(\"Already a float\")\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "if type(df[\"term\"][0]) == type(\"str\"): \n",
    "    df[\"term\"]=df[\"term\"].str.strip(\"months\").astype(\"float\")\n",
    "else:\n",
    "    print(\"Already a float\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518209d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### hier wird eine dateityp zum zeitdatentyp geändert\n",
    "df[\"issue_d\"]= pd.to_datetime(df[\"issue_d\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a78a917",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"issue_d\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5ec807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "df['issue_d'] = pd.to_datetime(df[\"issue_d\"], format=\"%Y-%M-%D\")\n",
    "df['issue_d'] = df['issue_d'].map(datetime.datetime.toordinal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86fa96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hier werden die fehlenden daten durch wahrscheinliche daten ersetzt (mean,median,blaa)\n",
    "\n",
    "df[\"open_acc\"].fillna(df[\"open_acc\"].median(),inplace=True)\n",
    "df[\"annual_inc\"].fillna(df[\"annual_inc\"].median().round(2),inplace=True)\n",
    "df[\"emp_length\"].fillna(\"no info at all\", inplace=True)\n",
    "df[\"pub_rec_bankruptcies\"].fillna(0.0, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6246281",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d9ab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corrwith(df[\"open_acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d88909",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.corr().shape)\n",
    "fig= plt.figure(figsize=(20,20))\n",
    "sns.heatmap(df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88c90dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### hier werden dummies erstellt\n",
    "\n",
    "df_dummie=pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "\n",
    "df_y_sub_grade= pd.get_dummies(y_target[\"sub_grade\"], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535ddd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1141c34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Modell\n",
    "yy=y_target[\"loan_status\"]\n",
    "X= df_dummie\n",
    "\n",
    "y_01= [\"Fully Paid\", \"Charged Off\"]\n",
    "#y=y.apply(lambda y: 1 if y == y_01[1] else 0)\n",
    "y= yy.apply(lambda y: 1 if y == y_01[0] else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276d94f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store X y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8392acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64724bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e380aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Naiv-estimator\n",
    "\n",
    "\n",
    "# TODO: Total number of records\n",
    "n_records = len(X)\n",
    "\n",
    "# TODO: Number of records where individual's income is more than $50,000\n",
    "fully_paid = y.sum()\n",
    "\n",
    "# TODO: Number of records where individual's income is at most $50,000\n",
    "charged_off = n_records - fully_paid\n",
    "\n",
    "# TODO: Percentage of individuals whose income is more than $50,000\n",
    "greater_percent = 100 * fully_paid / n_records\n",
    "\n",
    "# Print the results\n",
    "print (\"Total number of records: {}\".format(n_records))\n",
    "print (\"Individuals has paid her credit fully: {}\".format(fully_paid))\n",
    "print (\"Individuals hasn't paid her credit: {}\".format(charged_off))\n",
    "print (\"Percentage of individuals that paid ther credit: {:.2f}%\".format(greater_percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bd2278",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60b2922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size = 0.4, random_state = 70, stratify= y)\n",
    "\n",
    "# Show the results of the split\n",
    "print (\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print (\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a848447c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### skalieren\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# Initialize a scaler, then apply it to the features\n",
    "scaler = MinMaxScaler()\n",
    "numerical = ['loan_amnt', 'term', 'int_rate', 'installment', 'annual_inc',\"issue_d\",\"dti\",\"open_acc\",\"revol_bal\",\"pub_rec_bankruptcies\" ]\n",
    "X_train[numerical] = scaler.fit_transform(X_train[numerical])\n",
    "X_test[numerical] = scaler.transform(X_test[numerical])\n",
    "\n",
    "# Show an example of a record with scaling applied\n",
    "X_train[numerical].sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83790dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ecb31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "####fit von log reg\n",
    "\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1718eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(lr.coef_);\n",
    "#print(lr.intercept_);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051238db",
   "metadata": {},
   "outputs": [],
   "source": [
    "### predic\n",
    "\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516b57dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(cm)\n",
    "cp= classification_report(y_test,y_pred)\n",
    "print(cp)\n",
    "#acs=accuracy_score((y_test,y_pred))\n",
    "#print(acs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b52fa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## DecisionTree\n",
    "dtc = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23ee9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0be6c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dtc=dtc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57187b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,y_pred_dtc)\n",
    "print(cm)\n",
    "cp= classification_report(y_test,y_pred_dtc)\n",
    "print(cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ce9972",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r X_train X_test y_grade_train y_grade_test\n",
    "\n",
    "y_train = y_grade_train\n",
    "y_test = y_grade_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Funktion to printe the scores\n",
    "def score_print(y,y_pred):\n",
    "    \n",
    "    cm = confusion_matrix(y,y_pred)\n",
    "    print(cm)\n",
    "    cp= classification_report(y,y_pred)\n",
    "    print(cp)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grades = pd.DataFrame(y_train.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 57071\n",
      "Individuals have grades:       0\n",
      "G  8265\n",
      "F  8192\n",
      "A  8155\n",
      "E  8145\n",
      "C  8128\n",
      "D  8116\n",
      "B  8070\n",
      "Individuals have most likely grade: G\n",
      "Individuals have most likely grade with percent: 14.48%\n"
     ]
    }
   ],
   "source": [
    "###### Naiv-estimator\n",
    "\n",
    "# TODO: Total number of records\n",
    "n_records = len(y_train)\n",
    "\n",
    "# TODO: Different grades\n",
    "grades = pd.DataFrame(y_train.value_counts())\n",
    "\n",
    "# TODO: Mmost frequent grade \n",
    "most_frequent_grade = grades[grades[0] == int(grades.max())].index.tolist()[0]\n",
    "\n",
    "# TODO: Percentage of individuals whose income is more than $50,000\n",
    "percent = float(100 * grades.max() / n_records)\n",
    "\n",
    "# Print the results\n",
    "print (\"Total number of records: {}\".format(n_records))\n",
    "print (\"Individuals have grades: {}\".format(grades))\n",
    "print (\"Individuals have most likely grade: {}\".format(most_frequent_grade))\n",
    "print (\"Individuals have most likely grade with percent: {:.2f}%\".format(percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2470   75    0    0    0    0    0]\n",
      " [  68 2837  193    0    0    0    0]\n",
      " [   1  117 1860  208    0    0    0]\n",
      " [   2    0  145 1181  176    0    0]\n",
      " [   1    0    0  118  625  105    0]\n",
      " [   0    0    0    0   45  243   37]\n",
      " [   0    0    0    0    0   22  105]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.97      0.97      0.97      2545\n",
      "           B       0.94      0.92      0.93      3098\n",
      "           C       0.85      0.85      0.85      2186\n",
      "           D       0.78      0.79      0.78      1504\n",
      "           E       0.74      0.74      0.74       849\n",
      "           F       0.66      0.75      0.70       325\n",
      "           G       0.74      0.83      0.78       127\n",
      "\n",
      "    accuracy                           0.88     10634\n",
      "   macro avg       0.81      0.83      0.82     10634\n",
      "weighted avg       0.88      0.88      0.88     10634\n",
      "\n"
     ]
    }
   ],
   "source": [
    "####fit von log reg\n",
    "\n",
    "lr = LogisticRegression(max_iter=10000, C = 2.0, random_state=70)\n",
    "lr.fit(X_train, y_train)\n",
    "lr.score(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "score_print(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7997  158    0    0    0    0    0]\n",
      " [ 152 7519  399    0    0    0    0]\n",
      " [   3  241 7365  519    0    0    0]\n",
      " [   3    1  426 6957  729    0    0]\n",
      " [   3    3    4  685 6673  777    0]\n",
      " [   0    0    0    0  876 6574  742]\n",
      " [   0    0    0    0    0  650 7615]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.98      0.98      0.98      8155\n",
      "           B       0.95      0.93      0.94      8070\n",
      "           C       0.90      0.91      0.90      8128\n",
      "           D       0.85      0.86      0.85      8116\n",
      "           E       0.81      0.82      0.81      8145\n",
      "           F       0.82      0.80      0.81      8192\n",
      "           G       0.91      0.92      0.92      8265\n",
      "\n",
      "    accuracy                           0.89     57071\n",
      "   macro avg       0.89      0.89      0.89     57071\n",
      "weighted avg       0.89      0.89      0.89     57071\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score_print(y_train,lr.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e14aed01f57e2f30c4ad33bfe147e3add576437b8baa5fa8c8b958544bcab44"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
